{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudcard answers\n",
    "- **Can all models we learned be used to impute missing values? Should we compare different models when trying to impute the missing values?**\n",
    "    - do you mean in the iterative imputer?\n",
    "    - I recommend using non-deterministic ML algorithms in there like a random forest\n",
    "- **can you elaborate \"early_stopping_rounds\"**\n",
    "- **\"What's the eval_set=[(df_CV, y_CV)] in the XGB do? Sort of misunderstanding here**\n",
    "    - check out [here](https://xgboost.readthedocs.io/en/latest/python/python_intro.html) and [here](https://mljar.com/blog/xgboost-early-stopping/)\n",
    "- **How can missingness affect the correlation with the target variable, and how is this beneficial in the XGBoost model?**\n",
    "    - here is a hypothetical example:\n",
    "    - you have a balanced classification problem (50% in class 0 and 50% in class 1)\n",
    "    - one feature contains missing values\n",
    "    - you see in the training set that points with 90% of the missing values belong to class 0, and 10% of points with missing values belong to class 1\n",
    "    - when you see a missing value in that feature in the test set for example, XGBoost will know that the chances of that happening is 90% so that point is more likely to belong to class 0 than to class 1\n",
    "- **For quiz 1, I rerun the LinearRegression estimator several times, I get the answers all the same. But the result of mine is not the same as my classmate's, a little bit different, I am a little confused.**\n",
    "    - something must be different, you would need to investigate this more closely\n",
    "- **I was a bit confused with the first quiz. My two imputed values in LinearRegression did not match the RFR as you mentioned it should.**\n",
    "    - you misunderstood, the LinReg results should not match the RFR results\n",
    "    - the LinReg results should remain the same if you rerun the same cell\n",
    "    - the RFR results will be different each time you rerun the cell\n",
    "- **if multivariate imputation with random forest shows low uncertainty, is it ok to continue multivariate imputation with a different model?**\n",
    "    - sure but by the time you figure that out, you are already done developing the ML pipeline\n",
    "- **Can we use XGBoost directly on the time series (non-iid) data? Or we need to remove the dependency among data points first?**\n",
    "    - if you create autoregressive features, you can use XGB\n",
    "    - XGB is not a neural network, you can't feed it one time series\n",
    "- **With multivar imputation, I'm unsure why its valuable to have a model that returns an imputation with differing values!**\n",
    "    - imputation is another source of uncertainty in your test score\n",
    "    - by creating several imputed datasets and test scores, you'll be able to measure the uncertainty\n",
    "- **can we use XGBoost with other models or are we restricted to using it when we have complicated missing value scenarios.**\n",
    "    - you can use it on any structured dataset, it doesn't need to contain missing values\n",
    "    - XGB is just another ML algorithm\n",
    "- **So, XGBoost is a regression model using random forest?**\n",
    "    - nope\n",
    "    - it can be both regression and classification\n",
    "    - it does not use a random forest, it uses decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Missing data, part 2</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>review simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- **Apply the reduced-features model (also called the pattern submodel approach)**\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's load the data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "# drop the ID\n",
    "df.drop(columns=['Id'],inplace=True)\n",
    "\n",
    "# the target variable\n",
    "y = df['SalePrice']\n",
    "df.drop(columns=['SalePrice'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = df.values\n",
    "print(X.shape)\n",
    "# the feature names\n",
    "ftrs = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 79)\n",
      "(292, 79)\n",
      "(292, 79)\n"
     ]
    }
   ],
   "source": [
    "# let's split to train, CV, and test\n",
    "X_other, X_test, y_other, y_test = train_test_split(df, y, test_size=0.2, random_state=0)\n",
    "X_train, X_CV, y_train, y_CV = train_test_split(X_other, y_other, test_size=0.25, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_CV.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the various features\n",
    "cat_ftrs = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2',\\\n",
    "            'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation',\\\n",
    "           'Heating','CentralAir','Electrical','GarageType','PavedDrive','MiscFeature','SaleType','SaleCondition']\n",
    "ordinal_ftrs = ['LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\\\n",
    "               'BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish',\\\n",
    "               'GarageQual','GarageCond','PoolQC','Fence']\n",
    "ordinal_cats = [['Reg','IR1','IR2','IR3'],['AllPub','NoSewr','NoSeWa','ELO'],['Gtl','Mod','Sev'],\\\n",
    "               ['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Po','Fa','TA','Gd','Ex'],['NA','No','Mn','Av','Gd'],['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\\\n",
    "               ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Unf','RFn','Fin'],['NA','Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\n",
    "               ['NA','Fa','TA','Gd','Ex'],['NA','MnWw','GdWo','MnPrv','GdPrv']]\n",
    "num_ftrs = ['MSSubClass','LotFrontage','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd',\\\n",
    "             'MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\\\n",
    "             'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n",
    "             'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','WoodDeckSF',\\\n",
    "             'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "# ordinal encoder\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='constant',fill_value='NA')),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 221)\n",
      "(292, 221)\n",
      "(292, 221)\n"
     ]
    }
   ],
   "source": [
    "# fit_transform the training set\n",
    "X_prep = preprocessor.fit_transform(X_train)\n",
    "# little hacky, but collect feature names\n",
    "feature_names = preprocessor.transformers_[0][-1] + \\\n",
    "                list(preprocessor.named_transformers_['cat'][1].get_feature_names(cat_ftrs)) + \\\n",
    "                preprocessor.transformers_[2][-1]\n",
    "\n",
    "df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "print(df_train.shape)\n",
    "\n",
    "# transform the CV\n",
    "df_CV = preprocessor.transform(X_CV)\n",
    "df_CV = pd.DataFrame(data=df_CV,columns = feature_names)\n",
    "print(df_CV.shape)\n",
    "\n",
    "# transform the test\n",
    "df_test = preprocessor.transform(X_test)\n",
    "df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduced-features model (or pattern submodel approach)\n",
    "- first described in 2007 in a [JMLR article](http://www.jmlr.org/papers/v8/saar-tsechansky07a.html) as the reduced features model\n",
    "- in 2018, \"rediscovered\" as the pattern submodel approach in [Biostatistics](https://www.ncbi.nlm.nih.gov/pubmed/30203058)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>My test set:</center>\n",
    "\n",
    "| index \t| feature 1 \t| feature 2 \t| feature 3 \t| target var \t|\n",
    "|-------\t|:---------:\t|:---------:\t|:---------:\t|:----------:\t|\n",
    "| 0     \t|     <font color='red'>NA</font>    \t|     45    \t|     <font color='red'>NA</font>    \t|      0     \t|\n",
    "| 1     \t|     <font color='red'>NA</font>    \t|     <font color='red'>NA</font>    \t|     8     \t|      1     \t|\n",
    "| 2     \t|     12    \t|     6     \t|     34    \t|      0     \t|\n",
    "| 3     \t|     1     \t|     89    \t|     <font color='red'>NA</font>    \t|      0     \t|\n",
    "| 4     \t|     0     \t|     <font color='red'>NA</font>    \t|     47    \t|      1     \t|\n",
    "| 5     \t|    687    \t|     24    \t|     67    \t|      1     \t|\n",
    "| 6     \t|     <font color='red'>NA</font>    \t|     23    \t|     <font color='red'>NA</font>    \t|      1     \t|\n",
    "\n",
    "To predict points 0 and 6, I will use train and CV points that are complete in feature 2.\n",
    "\n",
    "To predict point 1, I will use train and CV points that are complete in feature 3.\n",
    "\n",
    "To predict point 2 and 5, I will use train and CV points that are complete in features 1-3.\n",
    "\n",
    "Etc. We will train as many models as the number of patterns in test/deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to determine the patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LotFrontage  MasVnrArea  GarageYrBlt\n",
      "0           True        True        False\n",
      "1          False       False        False\n",
      "2           True       False        False\n",
      "3          False       False        False\n",
      "4          False       False        False\n",
      "..           ...         ...          ...\n",
      "287        False       False        False\n",
      "288        False       False        False\n",
      "289        False       False        False\n",
      "290        False       False         True\n",
      "291        False       False        False\n",
      "\n",
      "[292 rows x 3 columns]\n",
      "(6, 3)\n",
      "[False False False] 223\n",
      "[False False  True] 21\n",
      "[False  True False] 1\n",
      "[ True False False] 44\n",
      "[ True False  True] 2\n",
      "[ True  True False] 1\n"
     ]
    }
   ],
   "source": [
    "mask = df_test[['LotFrontage','MasVnrArea','GarageYrBlt']].isnull()\n",
    "print(mask)\n",
    "\n",
    "unique_rows, counts = np.unique(mask, axis=0,return_counts=True)\n",
    "print(unique_rows.shape) # 6 patterns, we will train 6 models\n",
    "for i in range(len(counts)):\n",
    "    print(unique_rows[i],counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def xgb_model(X_train, Y_train, X_CV, y_CV, X_test, y_test, verbose=1):\n",
    "\n",
    "    # make into row vectors to avoid an obnoxious sklearn/xgb warning\n",
    "    Y_train = np.reshape(np.array(Y_train), (1, -1)).ravel()\n",
    "    y_CV = np.reshape(np.array(y_CV), (1, -1)).ravel()\n",
    "    y_test = np.reshape(np.array(y_test), (1, -1)).ravel()\n",
    "\n",
    "    XGB = xgboost.XGBRegressor(n_jobs=1)\n",
    "    \n",
    "    # find the best parameter set\n",
    "    param_grid = {\"learning_rate\": [0.03],\n",
    "                  \"n_estimators\": [10000],\n",
    "                  \"seed\": [0],\n",
    "                  #\"reg_alpha\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  #\"reg_lambda\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  \"missing\": [np.nan], \n",
    "                  #\"max_depth\": [1,3,10,30,100,],\n",
    "                  \"colsample_bytree\": [0.9],              \n",
    "                  \"subsample\": [0.66]}\n",
    "\n",
    "    pg = ParameterGrid(param_grid)\n",
    "\n",
    "    scores = np.zeros(len(pg))\n",
    "\n",
    "    for i in range(len(pg)):\n",
    "        if verbose >= 5:\n",
    "            print(\"Param set \" + str(i + 1) + \" / \" + str(len(pg)))\n",
    "        params = pg[i]\n",
    "        XGB.set_params(**params)\n",
    "        eval_set = [(X_CV, y_CV)]\n",
    "        XGB.fit(X_train, Y_train,\n",
    "                early_stopping_rounds=50, eval_set=eval_set, verbose=False)# with early stopping\n",
    "        y_CV_pred = XGB.predict(X_CV, ntree_limit=XGB.best_ntree_limit)\n",
    "        scores[i] = mean_squared_error(y_CV,y_CV_pred)\n",
    "\n",
    "    best_params = np.array(pg)[scores == np.max(scores)]\n",
    "    if verbose >= 4:\n",
    "        print('Test set max score and best parameters are:')\n",
    "        print(np.max(scores))\n",
    "        print(best_params)\n",
    "\n",
    "    # test the model on the test set with best parameter set\n",
    "    XGB.set_params(**best_params[0])\n",
    "    XGB.fit(X_train,Y_train,\n",
    "            early_stopping_rounds=50,eval_set=eval_set, verbose=False)\n",
    "    y_test_pred = XGB.predict(X_test, ntree_limit=XGB.best_ntree_limit)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print ('The MSE is:',mean_squared_error(y_test,y_test_pred))\n",
    "    if verbose >= 2:\n",
    "        print ('The predictions are:')\n",
    "        print (y_test_pred)\n",
    "    if verbose >= 3:\n",
    "        print(\"Feature importances:\")\n",
    "        print(XGB.feature_importances_)\n",
    "\n",
    "    return (mean_squared_error(y_test,y_test_pred), y_test_pred, XGB.feature_importances_)\n",
    "\n",
    "# Function: Reduced-feature XGB model\n",
    "# all the inputs need to be pandas DataFrame\n",
    "def reduced_feature_xgb(X_train, Y_train, X_CV, y_CV, X_test, y_test):\n",
    "    \n",
    "    # find all unique patterns of missing value in test set\n",
    "    mask = X_test.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_y_test_pred = pd.DataFrame()\n",
    "    \n",
    "    print('there are', len(unique_rows), 'unique missing value patterns.')\n",
    "    \n",
    "    # divide test sets into subgroups according to the unique patterns\n",
    "    for i in range(len(unique_rows)):\n",
    "        print ('working on unique pattern', i)\n",
    "        ## generate X_test subset that matches the unique pattern i\n",
    "        sub_X_test = pd.DataFrame()\n",
    "        sub_y_test = pd.Series(dtype=float)\n",
    "        for j in range(len(mask)): # check each row in mask\n",
    "            row_mask = np.array(mask.iloc[j])\n",
    "            if np.array_equal(row_mask, unique_rows[i]): # if the pattern matches the ith unique pattern\n",
    "                sub_X_test = sub_X_test.append(X_test.iloc[j])# append the according X_test row j to the subset\n",
    "                sub_y_test = sub_y_test.append(y_test.iloc[[j]])# append the according y_test row j\n",
    "        sub_X_test = sub_X_test[X_test.columns[~unique_rows[i]]]\n",
    "        \n",
    "        ## choose the according reduced features for subgroups\n",
    "        sub_X_train = pd.DataFrame()\n",
    "        sub_Y_train = pd.DataFrame()\n",
    "        sub_X_CV = pd.DataFrame()\n",
    "        sub_y_CV = pd.DataFrame()\n",
    "        # 1.cut the feature columns that have nans in the according sub_X_test\n",
    "        sub_X_train = X_train[X_train.columns[~unique_rows[i]]]\n",
    "        sub_X_CV = X_CV[X_CV.columns[~unique_rows[i]]]\n",
    "        # 2.cut the rows in the sub_X_train and sub_X_CV that have any nans\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_CV = sub_X_CV.dropna()   \n",
    "        # 3.cut the sub_Y_train and sub_y_CV accordingly\n",
    "        sub_Y_train = Y_train.iloc[sub_X_train.index]\n",
    "        sub_y_CV = y_CV.iloc[sub_X_CV.index]\n",
    "        \n",
    "        # run XGB\n",
    "        sub_y_test_pred = xgb_model(sub_X_train, sub_Y_train, sub_X_CV, \n",
    "                                       sub_y_CV, sub_X_test, sub_y_test, verbose=0)\n",
    "        sub_y_test_pred = pd.DataFrame(sub_y_test_pred[1],columns=['sub_y_test_pred'],\n",
    "                                          index=sub_y_test.index)\n",
    "        print('   RMSE:',np.sqrt(mean_squared_error(sub_y_test,sub_y_test_pred)))\n",
    "        # collect the test predictions\n",
    "        all_y_test_pred = all_y_test_pred.append(sub_y_test_pred)\n",
    "        \n",
    "    # rank the final y_test_pred according to original y_test index\n",
    "    all_y_test_pred = all_y_test_pred.sort_index()\n",
    "    y_test = y_test.sort_index()\n",
    "               \n",
    "    # get global RMSE\n",
    "    total_RMSE = np.sqrt(mean_squared_error(y_test,all_y_test_pred))\n",
    "    total_R2 =  r2_score(y_test,all_y_test_pred)\n",
    "    return total_RMSE, total_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6 unique missing value patterns.\n",
      "working on unique pattern 0\n",
      "   RMSE: 35277.53667892742\n",
      "working on unique pattern 1\n",
      "   RMSE: 11607.856743646213\n",
      "working on unique pattern 2\n",
      "   RMSE: 1134.5625\n",
      "working on unique pattern 3\n",
      "   RMSE: 18366.394043603428\n",
      "working on unique pattern 4\n",
      "   RMSE: 18521.340554971906\n",
      "working on unique pattern 5\n",
      "   RMSE: 65343.46875\n",
      "final RMSE: 32061.238747816282\n",
      "final R2: 0.8511518443924384\n"
     ]
    }
   ],
   "source": [
    "RMSE, R2 = reduced_feature_xgb(df_train, y_train, df_CV, y_CV, df_test, y_test)\n",
    "print('final RMSE:', RMSE)\n",
    "print('final R2:', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Missing data, part 2</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>review simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- **Decide which approach is best for your dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which approach is best for my data?\n",
    "- **XGB**: run $n$ XGB models with $n$ different seeds\n",
    "- **imputation**: prepare $n$ different imputations and run $n$ XGB models on them\n",
    "- **reduced-features**: run $n$ reduced-features model with $n$ different seeds\n",
    "- rank the three methods based on how significantly different the corresponding mean scores are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on imbalanced datasets\n",
    "- we learnt that a classification problem is imbalanced if more than 90-95% of the points belong to one class (class 0) and only a small fraction of the points belong to the other class (class 1)\n",
    "    - fraud detection\n",
    "    - sick or not sick (usually by far most people are not sick)\n",
    "- we learnt to not use a metric that relies on the True Negatives in the confusion matrix\n",
    "    - no accuracy or ROC\n",
    "    - use f_beta or the precision-recall curve instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else can I do if I have an imbalanced dataset?\n",
    "- most (but not all) classification algorithms we covered have a parameter called `class_weight` which allows you to assign more weight to the class 1 point\n",
    "    - a misclassified class 1 point will contribute more to the cost function than a misclassified class 0 point\n",
    "    - read the manual on `class_weight` because the different algorithms have slightly different definitions for this parameter\n",
    "    - usually you can use `None`, `balanced`, or manually define what the class weight should be\n",
    "    - it is worthwhile to tune this parameter if you have an imbalanced dataset\n",
    "- resample/augment the dataset\n",
    "    - SMOTE (Synthetic Minority Over-sampling Technique), see the [paper](https://arxiv.org/abs/1106.1813)\n",
    "    - to improve the balance of the problem, new class 1 examples are synthesized from the existing examples\n",
    "    - be careful though!\n",
    "        - while resampling improves the balance of the dataset, the results of the model can be misleading\n",
    "        - when you deploy the model, the incoming data will be as imbalanced as the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misleading results with resampling\n",
    "- let's assume you have an imbalanced dataset with 99% of points in class 0 and 1% of points in class 1\n",
    "- you resample it such that the improved class balance is 50-50\n",
    "- here the confusion matrix of the trained model:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN): 45%</b></td>\n",
    "        <td><b>False Positive (FP): 5%</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN): 5%</b></td>\n",
    "        <td><b>True Positive (TP): 45%</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "- 90% accuracy which is well above the 50% baseline accuracy!\n",
    "- the precision, recall, and f1 scores are all 0.9.\n",
    "- it looks great, doesn't it?\n",
    "- let's rewrite the confusion matrix to reflect rates on the Condition Negative and Condition Positive points!\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0) 50% of the points</td>\n",
    "        <td><b>90% of CNs are correctly classified</b></td>\n",
    "        <td><b>10% of CNs are incorrectly classified</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1) 50% of the points</td>\n",
    "        <td><b>10% of CPs are incorrectly classified</b></td>\n",
    "        <td><b>90% of CPs are correctly classified</b></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's deploy this model\n",
    "\n",
    "- the incoming data has the same balance as the original dataset (99% to 1%)\n",
    "- let's assume we have 1e5 new points, 9.9e4 belongs to class 0, 1000 belongs to class 1\n",
    "- what will be the numbers in the confusion matrix?\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0) 99000 points</td>\n",
    "        <td><b>True Negative (TN): 99000 * 0.9 = 89100 </b></td>\n",
    "        <td><b>False Positive (FP): 99000 * 0.1 = 9900 </b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1) 1000 points</td>\n",
    "        <td><b>False Negative (FN): 1000 * 0.1 = 100</b></td>\n",
    "        <td><b>True Positive (TP): 1000 * 0.9 = 900</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "- the accuracy of this model is still 0.90 but now it is well below the baseline of 0.99!\n",
    "- recall is good (0.90) but the precision is not great (~0.083)\n",
    "- the f1 score is ~0.15\n",
    "- the false positives are overwhelming\n",
    "- this is why you need to be careful with resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudcard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
