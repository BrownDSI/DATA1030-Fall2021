{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Missing data </center>\n",
    "### By the end of this lecture, you will be able to\n",
    "- Describe and compare the three main types of missingness patterns\n",
    "- Evaluate simple approaches for handling missing values\n",
    "- Apply multivariate imputation to a dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing values often occur in datasets\n",
    "- survey data: not everyone answers all the questions\n",
    "- medical data: not all tests/treatments/etc are performed on all patients\n",
    "- sensor can be offline or malfunctioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing values are an issue for multiple reasons\n",
    "\n",
    "#### Concenptual reason\n",
    "- missing values can introduce biases\n",
    "    - bias: the samples (the data points) are not representative of the underlying distribution/population\n",
    "    - any conclusion drawn from a biased dataset is also biased.\n",
    "    - rich people tend to not fill out survey questions about their salaries and the mean salary estimated from survey data tend to be lower than true value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Practical reason\n",
    "- missing values (NaN, NA, inf) are incompatible with sklearn\n",
    "   - all values in an array need to be numerical otherwise sklearn will throw a *ValueError*\n",
    "- there are a few supervised ML techniques that work with missing values (e.g., XGBoost)\n",
    "   - we will cover those later this semester during a follow-up lecture on missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- **Describe and compare the three main types of missingness patterns**\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation to a dataset</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Missing data patterns\n",
    "\n",
    "- MCAR - Missing Complete At Random\n",
    "- MAR - Missing At Random\n",
    "- MNAR - Missing Not At Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MCAR - Missing Complete At Random\n",
    "\n",
    "- the reason the values are missing are related to an unobserved variable\n",
    "- in other words, the missingness pattern does not correlate with any of the observed variables\n",
    "- the data sample is still representative of the underlying distribution/population\n",
    "- your best case scenario but usually rare\n",
    "\n",
    "## MCAR examples\n",
    "- some people randomly fail to fill in some values in a survey \n",
    "- sensor randomly malfunctions\n",
    "- apps, websites are unavailable sometimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MAR - Missing At Random\n",
    "\n",
    "- Name is misleading! Better name would be 'Missing Conditionally at Random' but the MCAR acronym is taken. \n",
    "- the reason why values are missing in one feature is correlated another feature\n",
    "\n",
    "## MAR examples\n",
    "- missing value in blood pressure data conditional on age\n",
    "   - older people are more likely to have their blood pressure measured during a regular check-up than younger people\n",
    "- males are less likely to fill in a depression survey\n",
    "   - this has nothing to do with their level of depression after accounting for maleness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MNAR - Missing Not At Random\n",
    "\n",
    "- the reason the feature contains missing values is related to the value of the feature itself\n",
    "- most severe case of missingness!\n",
    "- not many ML approaches can deal with this pattern correctly\n",
    "\n",
    "## MNAR examples\n",
    "- depressed people are less likely to fill out a survey on depression because of their level of depression\n",
    "- rich people don't fill out survey info on  their salaries because they are rich and don't want to reveal how much they earn\n",
    "- temperature sensor doesn't work because the observed temperature is outside of range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MAR can be identifed by a statistical test\n",
    "\n",
    "- [Little, 1988](https://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478722)\n",
    "- pdf of article in week4 folder\n",
    "- the approach:\n",
    "    - given a feature with missing values, it creates a mask which is 0 if feature is not missing and 1 if feature is missing\n",
    "    - loop through the other features in the dataset\n",
    "        - collect the other feature values if mask = 0 and if mask = 1, these are our two samples\n",
    "        - use a statistical test to check if the two samples are different\n",
    "    - if the answer is yes, MAR is at least partially responsible for the missing values\n",
    "    - if answer is no, we might have MCAR or MNAR\n",
    "       - the test can't distinguish MCAR from MNAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What to do when you get a dataset with missing values?\n",
    "- it can be challenging to infer the missingness pattern from an incomplete dataset\n",
    "   - you might work with a subject matter expert who can tell you or guess why some values are missing with some confidece\n",
    "   - but as far as I know, it is impossible to infer the missingness patterns just from a dataset\n",
    "- do some simple diagnostics!\n",
    "   - which features contain missing values?\n",
    "   - what fraction of the values are missing in each feature?\n",
    "   - are the features categorical or continuous?\n",
    "   - what fraction of points contain at least one missing feature value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "- kaggle house price dataset\n",
    "- check out the train.csv and the dataset description in the `data` folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's load the data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "# drop the ID\n",
    "df.drop(columns=['Id'],inplace=True)\n",
    "\n",
    "# the target variable\n",
    "y = df['SalePrice']\n",
    "df.drop(columns=['SalePrice'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = df\n",
    "print(X.shape)\n",
    "# the feature names\n",
    "ftrs = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions: (1460, 79)\n",
      "fraction of missing values in features:\n",
      "LotFrontage     0.177397\n",
      "Alley           0.937671\n",
      "MasVnrType      0.005479\n",
      "MasVnrArea      0.005479\n",
      "BsmtQual        0.025342\n",
      "BsmtCond        0.025342\n",
      "BsmtExposure    0.026027\n",
      "BsmtFinType1    0.025342\n",
      "BsmtFinType2    0.026027\n",
      "Electrical      0.000685\n",
      "FireplaceQu     0.472603\n",
      "GarageType      0.055479\n",
      "GarageYrBlt     0.055479\n",
      "GarageFinish    0.055479\n",
      "GarageQual      0.055479\n",
      "GarageCond      0.055479\n",
      "PoolQC          0.995205\n",
      "Fence           0.807534\n",
      "MiscFeature     0.963014\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "LotFrontage     float64\n",
      "Alley            object\n",
      "MasVnrType       object\n",
      "MasVnrArea      float64\n",
      "BsmtQual         object\n",
      "BsmtCond         object\n",
      "BsmtExposure     object\n",
      "BsmtFinType1     object\n",
      "BsmtFinType2     object\n",
      "Electrical       object\n",
      "FireplaceQu      object\n",
      "GarageType       object\n",
      "GarageYrBlt     float64\n",
      "GarageFinish     object\n",
      "GarageQual       object\n",
      "GarageCond       object\n",
      "PoolQC           object\n",
      "Fence            object\n",
      "MiscFeature      object\n",
      "dtype: object\n",
      "fraction of points with missing values: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('data dimensions:',df.shape)\n",
    "perc_missing_per_ftr = df.isnull().sum(axis=0)/df.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(df[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(df.isnull().sum(axis=1)!=0)/df.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 7, Quiz 2 on canvas\n",
    "True or false?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe and compare the three main types of missingness patterns</font>\n",
    "- **Evaluate simple approaches for handling missing values**\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation to a dataset</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple approaches for handling missing values\n",
    "\n",
    "- exclude points or features with missing values\n",
    "- categorical feature: treat missing values as another category\n",
    "- continuous feature: sklearn's SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exclude points or features with missing values\n",
    "- easy to do with pandas\n",
    "- it can be an ACCEPTABLE approach:\n",
    "    - only small fraction of points contain missing values (maybe just a few percent?)\n",
    "    - all missing values occur in one or a few features and you have good reason to believe those features will not be important anyway\n",
    "    - it is OK to ignore a point with missing values when the model is deployed  \n",
    "       - not always the case! think of medical or finance problems!\n",
    "- due to the smaller sample size, the confidence of your model might suffer but usually not a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Drop points or features with missing values\n",
    "- not OK for the house price dataset because all points contain some NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n",
      "(0, 79)\n",
      "(1460, 60)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# by default, rows/points are dropped\n",
    "df_r = df.dropna()\n",
    "print(df_r.shape)\n",
    "# drop features with missing values\n",
    "df_c = df.dropna(axis=1)\n",
    "print(df_c.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Categorical feature: treat missing values as another category\n",
    "\n",
    "- the BEST thing you can do!\n",
    "- already covered in the preprocessing lecture (one hot encoding)\n",
    "- example: missing values in gender\n",
    "    - if survey only has options for male/female, missing values are likely because those people are outside the gender binary\n",
    "    - it is a bad idea to impute (try to guess male or female and thus boxing them into the binary)\n",
    "- example: native country in the adult data\n",
    "    - missing data are represented as ` ?`\n",
    "    - a one-hot encoded feature was assigned to the missing category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's load the data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "# drop the ID\n",
    "df.drop(columns=['Id'],inplace=True)\n",
    "\n",
    "# the target variable\n",
    "y = df['SalePrice']\n",
    "df.drop(columns=['SalePrice'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = df.values\n",
    "print(X.shape)\n",
    "# the feature names\n",
    "ftrs = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 79)\n",
      "(292, 79)\n",
      "(292, 79)\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "# let's split to train, CV, and test\n",
    "X_train, X_other, y_train, y_other = train_test_split(df, y, train_size=0.6, random_state=random_state)\n",
    "X_CV, X_test, y_CV, y_test = train_test_split(X_other, y_other, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_CV.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the various features\n",
    "cat_ftrs = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2',\\\n",
    "            'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation',\\\n",
    "           'Heating','CentralAir','Electrical','GarageType','PavedDrive','MiscFeature','SaleType','SaleCondition']\n",
    "ordinal_ftrs = ['LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\\\n",
    "               'BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish',\\\n",
    "               'GarageQual','GarageCond','PoolQC','Fence']\n",
    "ordinal_cats = [['Reg','IR1','IR2','IR3'],['AllPub','NoSewr','NoSeWa','ELO'],['Gtl','Mod','Sev'],\\\n",
    "               ['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Po','Fa','TA','Gd','Ex'],['NA','No','Mn','Av','Gd'],['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\\\n",
    "               ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Unf','RFn','Fin'],['NA','Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\n",
    "               ['NA','Fa','TA','Gd','Ex'],['NA','MnWw','GdWo','MnPrv','GdPrv']]\n",
    "num_ftrs = ['MSSubClass','LotFrontage','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd',\\\n",
    "             'MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\\\n",
    "             'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n",
    "             'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','WoodDeckSF',\\\n",
    "             'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# one-hot encoder\n",
    "# We need to replace the NaN with a string first!\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "# ordinal encoder\n",
    "# We need to replace the NaN with a string first!\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='constant',fill_value='NA')),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 223)\n",
      "(292, 223)\n",
      "(292, 223)\n",
      "['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'MSZoning_C (all)', 'MSZoning_FV', 'MSZoning_RH', 'MSZoning_RL', 'MSZoning_RM', 'Street_Grvl', 'Street_Pave', 'Alley_Grvl', 'Alley_Pave', 'Alley_missing', 'LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low', 'LandContour_Lvl', 'LotConfig_Corner', 'LotConfig_CulDSac', 'LotConfig_FR2', 'LotConfig_FR3', 'LotConfig_Inside', 'Neighborhood_Blmngtn', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_IDOTRR', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'Condition1_Artery', 'Condition1_Feedr', 'Condition1_Norm', 'Condition1_PosA', 'Condition1_PosN', 'Condition1_RRAe', 'Condition1_RRAn', 'Condition1_RRNe', 'Condition1_RRNn', 'Condition2_Artery', 'Condition2_Feedr', 'Condition2_Norm', 'Condition2_PosN', 'Condition2_RRAe', 'Condition2_RRAn', 'BldgType_1Fam', 'BldgType_2fmCon', 'BldgType_Duplex', 'BldgType_Twnhs', 'BldgType_TwnhsE', 'HouseStyle_1.5Fin', 'HouseStyle_1.5Unf', 'HouseStyle_1Story', 'HouseStyle_2.5Fin', 'HouseStyle_2.5Unf', 'HouseStyle_2Story', 'HouseStyle_SFoyer', 'HouseStyle_SLvl', 'RoofStyle_Flat', 'RoofStyle_Gable', 'RoofStyle_Gambrel', 'RoofStyle_Hip', 'RoofStyle_Mansard', 'RoofStyle_Shed', 'RoofMatl_ClyTile', 'RoofMatl_CompShg', 'RoofMatl_Metal', 'RoofMatl_Roll', 'RoofMatl_Tar&Grv', 'RoofMatl_WdShake', 'RoofMatl_WdShngl', 'Exterior1st_AsbShng', 'Exterior1st_AsphShn', 'Exterior1st_BrkComm', 'Exterior1st_BrkFace', 'Exterior1st_CBlock', 'Exterior1st_CemntBd', 'Exterior1st_HdBoard', 'Exterior1st_MetalSd', 'Exterior1st_Plywood', 'Exterior1st_Stone', 'Exterior1st_Stucco', 'Exterior1st_VinylSd', 'Exterior1st_Wd Sdng', 'Exterior1st_WdShing', 'Exterior2nd_AsbShng', 'Exterior2nd_AsphShn', 'Exterior2nd_Brk Cmn', 'Exterior2nd_BrkFace', 'Exterior2nd_CBlock', 'Exterior2nd_CmentBd', 'Exterior2nd_HdBoard', 'Exterior2nd_ImStucc', 'Exterior2nd_MetalSd', 'Exterior2nd_Other', 'Exterior2nd_Plywood', 'Exterior2nd_Stone', 'Exterior2nd_Stucco', 'Exterior2nd_VinylSd', 'Exterior2nd_Wd Sdng', 'Exterior2nd_Wd Shng', 'MasVnrType_BrkCmn', 'MasVnrType_BrkFace', 'MasVnrType_None', 'MasVnrType_Stone', 'MasVnrType_missing', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc', 'Foundation_Slab', 'Foundation_Stone', 'Foundation_Wood', 'Heating_Floor', 'Heating_GasA', 'Heating_GasW', 'Heating_Grav', 'Heating_OthW', 'Heating_Wall', 'CentralAir_N', 'CentralAir_Y', 'Electrical_FuseA', 'Electrical_FuseF', 'Electrical_FuseP', 'Electrical_SBrkr', 'Electrical_missing', 'GarageType_2Types', 'GarageType_Attchd', 'GarageType_Basment', 'GarageType_BuiltIn', 'GarageType_CarPort', 'GarageType_Detchd', 'GarageType_missing', 'PavedDrive_N', 'PavedDrive_P', 'PavedDrive_Y', 'MiscFeature_Gar2', 'MiscFeature_Shed', 'MiscFeature_TenC', 'MiscFeature_missing', 'SaleType_COD', 'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD', 'SaleType_ConLI', 'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD', 'SaleCondition_Abnorml', 'SaleCondition_AdjLand', 'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal', 'SaleCondition_Partial', 'LotShape', 'Utilities', 'LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence']\n"
     ]
    }
   ],
   "source": [
    "# fit_transform the training set\n",
    "X_prep = preprocessor.fit_transform(X_train)\n",
    "# little hacky, but collect feature names\n",
    "feature_names = preprocessor.transformers_[0][-1] + \\\n",
    "                list(preprocessor.named_transformers_['cat'][1].get_feature_names(cat_ftrs)) + \\\n",
    "                preprocessor.transformers_[2][-1]\n",
    "\n",
    "# you can convert the numpy array back to a data frame with the feature names if you want\n",
    "df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "print(df_train.shape)\n",
    "\n",
    "# transform the CV\n",
    "df_CV = preprocessor.transform(X_CV)\n",
    "df_CV = pd.DataFrame(data=df_CV,columns = feature_names)\n",
    "print(df_CV.shape)\n",
    "\n",
    "# transform the test\n",
    "df_test = preprocessor.transform(X_test)\n",
    "df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "print(df_test.shape)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions: (876, 223)\n",
      "fraction of missing values in features:\n",
      "LotFrontage    0.190639\n",
      "MasVnrArea     0.002283\n",
      "GarageYrBlt    0.052511\n",
      "dtype: float64\n",
      "data types of the features with missing values:\n",
      "LotFrontage    float64\n",
      "MasVnrArea     float64\n",
      "GarageYrBlt    float64\n",
      "dtype: object\n",
      "fraction of points with missing values: 0.23972602739726026\n"
     ]
    }
   ],
   "source": [
    "print('data dimensions:',df_train.shape)\n",
    "perc_missing_per_ftr = df_train.isnull().sum(axis=0)/df_train.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "print('data types of the features with missing values:')\n",
    "print(df_train[perc_missing_per_ftr[perc_missing_per_ftr > 0].index].dtypes)\n",
    "frac_missing = sum(df_train.isnull().sum(axis=1)!=0)/df_train.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 7, Quiz 3 on canvas\n",
    "The gender feature below contains missing values. Please explain how you would encode it and would be the output of the encoder. Do not write code. The goal of this quiz is to test your conceptual understanding so write text and the output array.\n",
    "\n",
    "gender = ['Male', 'Female', 'Male', NaN, NaN, 'Female']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continuous feature: sklearn's SimpleImputer\n",
    "\n",
    "- Imputation means you infer the missing values from the known part of the data\n",
    "- sklearn's SimpleImputer can do mean and median imputation\n",
    "- USUALLY A BAD IDEA!\n",
    "   - mean or median imputation decreases the variance of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std before imputation: 1.0\n",
      "std after imputation: 0.8996447802291788\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "si = SimpleImputer(strategy='mean')\n",
    "X_lot = si.fit_transform(df_train[['LotFrontage']])\n",
    "\n",
    "df_train['LotFrontage'].hist(bins=40,label = 'before imputation',alpha=0.5)\n",
    "plt.hist(X_lot,bins=40,label='after imputation',alpha=0.5)\n",
    "plt.xlabel('Lot frontage (standardized)')\n",
    "plt.ylabel('nr of houses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('std before imputation:',np.std(df_train['LotFrontage']))\n",
    "print('std after imputation:',np.std(X_lot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe and compare the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- **Apply multivariate imputation to a dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multivariate imputation\n",
    "\n",
    "- models each feature with missing values as a function of other features, and uses that estimate for imputation\n",
    "   - at each step, a feature column is designated as target variable y and the other feature columns are treated as inputs X\n",
    "   - a regressor is trained on (X, y) for known y\n",
    "   - then, the regressor is used to predict the missing values of y\n",
    "- paper [here](https://www.jstatsoft.org/article/view/v045i03) and pdf in folder\n",
    "- fails for MNAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it make sense to impute values?\n",
    "- what continuous features have missing values?\n",
    "- why are the values missing?\n",
    "   - health care: maybe a test was not performed on all patients, that's why some test results are missing\n",
    "      - would you feel comfortable guessing what the test results would have been if it had been performed?\n",
    "   - in the house price dataset, GarageYrBlt is one of the continuous features with missing values\n",
    "      - it is missing if the house has no garage!\n",
    "      - therefore an imputed GarageYrBlt value is meaningless \n",
    "- not always a good approach but it might work under some circumstances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class IterativeImputer in module sklearn.impute._iterative:\n",
      "\n",
      "class IterativeImputer(sklearn.impute._base._BaseImputer)\n",
      " |  IterativeImputer(estimator=None, *, missing_values=nan, sample_posterior=False, max_iter=10, tol=0.001, n_nearest_features=None, initial_strategy='mean', imputation_order='ascending', skip_complete=False, min_value=-inf, max_value=inf, verbose=0, random_state=None, add_indicator=False)\n",
      " |  \n",
      " |  Multivariate imputer that estimates each feature from all the others.\n",
      " |  \n",
      " |  A strategy for imputing missing values by modeling each feature with\n",
      " |  missing values as a function of other features in a round-robin fashion.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <iterative_imputer>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.21\n",
      " |  \n",
      " |  .. note::\n",
      " |  \n",
      " |    This estimator is still **experimental** for now: the predictions\n",
      " |    and the API might change without any deprecation cycle. To use it,\n",
      " |    you need to explicitly import ``enable_iterative_imputer``::\n",
      " |  \n",
      " |      >>> # explicitly require this experimental feature\n",
      " |      >>> from sklearn.experimental import enable_iterative_imputer  # noqa\n",
      " |      >>> # now you can import normally from sklearn.impute\n",
      " |      >>> from sklearn.impute import IterativeImputer\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object, default=BayesianRidge()\n",
      " |      The estimator to use at each step of the round-robin imputation.\n",
      " |      If ``sample_posterior`` is True, the estimator must support\n",
      " |      ``return_std`` in its ``predict`` method.\n",
      " |  \n",
      " |  missing_values : int, np.nan, default=np.nan\n",
      " |      The placeholder for the missing values. All occurrences of\n",
      " |      `missing_values` will be imputed. For pandas' dataframes with\n",
      " |      nullable integer dtypes with missing values, `missing_values`\n",
      " |      should be set to `np.nan`, since `pd.NA` will be converted to `np.nan`.\n",
      " |  \n",
      " |  sample_posterior : boolean, default=False\n",
      " |      Whether to sample from the (Gaussian) predictive posterior of the\n",
      " |      fitted estimator for each imputation. Estimator must support\n",
      " |      ``return_std`` in its ``predict`` method if set to ``True``. Set to\n",
      " |      ``True`` if using ``IterativeImputer`` for multiple imputations.\n",
      " |  \n",
      " |  max_iter : int, default=10\n",
      " |      Maximum number of imputation rounds to perform before returning the\n",
      " |      imputations computed during the final round. A round is a single\n",
      " |      imputation of each feature with missing values. The stopping criterion\n",
      " |      is met once `max(abs(X_t - X_{t-1}))/max(abs(X[known_vals])) < tol`,\n",
      " |      where `X_t` is `X` at iteration `t`. Note that early stopping is only\n",
      " |      applied if ``sample_posterior=False``.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance of the stopping condition.\n",
      " |  \n",
      " |  n_nearest_features : int, default=None\n",
      " |      Number of other features to use to estimate the missing values of\n",
      " |      each feature column. Nearness between features is measured using\n",
      " |      the absolute correlation coefficient between each feature pair (after\n",
      " |      initial imputation). To ensure coverage of features throughout the\n",
      " |      imputation process, the neighbor features are not necessarily nearest,\n",
      " |      but are drawn with probability proportional to correlation for each\n",
      " |      imputed target feature. Can provide significant speed-up when the\n",
      " |      number of features is huge. If ``None``, all features will be used.\n",
      " |  \n",
      " |  initial_strategy : str, default='mean'\n",
      " |      Which strategy to use to initialize the missing values. Same as the\n",
      " |      ``strategy`` parameter in :class:`~sklearn.impute.SimpleImputer`\n",
      " |      Valid values: {\"mean\", \"median\", \"most_frequent\", or \"constant\"}.\n",
      " |  \n",
      " |  imputation_order : str, default='ascending'\n",
      " |      The order in which the features will be imputed. Possible values:\n",
      " |  \n",
      " |      \"ascending\"\n",
      " |          From features with fewest missing values to most.\n",
      " |      \"descending\"\n",
      " |          From features with most missing values to fewest.\n",
      " |      \"roman\"\n",
      " |          Left to right.\n",
      " |      \"arabic\"\n",
      " |          Right to left.\n",
      " |      \"random\"\n",
      " |          A random order for each round.\n",
      " |  \n",
      " |  skip_complete : boolean, default=False\n",
      " |      If ``True`` then features with missing values during ``transform``\n",
      " |      which did not have any missing values during ``fit`` will be imputed\n",
      " |      with the initial imputation method only. Set to ``True`` if you have\n",
      " |      many features with no missing values at both ``fit`` and ``transform``\n",
      " |      time to save compute.\n",
      " |  \n",
      " |  min_value : float or array-like of shape (n_features,), default=-np.inf\n",
      " |      Minimum possible imputed value. Broadcast to shape (n_features,) if\n",
      " |      scalar. If array-like, expects shape (n_features,), one min value for\n",
      " |      each feature. The default is `-np.inf`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.23\n",
      " |         Added support for array-like.\n",
      " |  \n",
      " |  max_value : float or array-like of shape (n_features,), default=np.inf\n",
      " |      Maximum possible imputed value. Broadcast to shape (n_features,) if\n",
      " |      scalar. If array-like, expects shape (n_features,), one max value for\n",
      " |      each feature. The default is `np.inf`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.23\n",
      " |         Added support for array-like.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Verbosity flag, controls the debug messages that are issued\n",
      " |      as functions are evaluated. The higher, the more verbose. Can be 0, 1,\n",
      " |      or 2.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      The seed of the pseudo random number generator to use. Randomizes\n",
      " |      selection of estimator features if n_nearest_features is not None, the\n",
      " |      ``imputation_order`` if ``random``, and the sampling from posterior if\n",
      " |      ``sample_posterior`` is True. Use an integer for determinism.\n",
      " |      See :term:`the Glossary <random_state>`.\n",
      " |  \n",
      " |  add_indicator : boolean, default=False\n",
      " |      If True, a :class:`MissingIndicator` transform will stack onto output\n",
      " |      of the imputer's transform. This allows a predictive estimator\n",
      " |      to account for missingness despite imputation. If a feature has no\n",
      " |      missing values at fit/train time, the feature won't appear on\n",
      " |      the missing indicator even if there are missing values at\n",
      " |      transform/test time.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  initial_imputer_ : object of type :class:`~sklearn.impute.SimpleImputer`\n",
      " |      Imputer used to initialize the missing values.\n",
      " |  \n",
      " |  imputation_sequence_ : list of tuples\n",
      " |      Each tuple has ``(feat_idx, neighbor_feat_idx, estimator)``, where\n",
      " |      ``feat_idx`` is the current feature to be imputed,\n",
      " |      ``neighbor_feat_idx`` is the array of other features used to impute the\n",
      " |      current feature, and ``estimator`` is the trained estimator used for\n",
      " |      the imputation. Length is ``self.n_features_with_missing_ *\n",
      " |      self.n_iter_``.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iteration rounds that occurred. Will be less than\n",
      " |      ``self.max_iter`` if early stopping criterion was reached.\n",
      " |  \n",
      " |  n_features_with_missing_ : int\n",
      " |      Number of features with missing values.\n",
      " |  \n",
      " |  indicator_ : :class:`~sklearn.impute.MissingIndicator`\n",
      " |      Indicator used to add binary indicators for missing values.\n",
      " |      ``None`` if add_indicator is False.\n",
      " |  \n",
      " |  random_state_ : RandomState instance\n",
      " |      RandomState instance that is generated either from a seed, the random\n",
      " |      number generator or by `np.random`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SimpleImputer : Univariate imputation of missing values.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.experimental import enable_iterative_imputer\n",
      " |  >>> from sklearn.impute import IterativeImputer\n",
      " |  >>> imp_mean = IterativeImputer(random_state=0)\n",
      " |  >>> imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
      " |  IterativeImputer(random_state=0)\n",
      " |  >>> X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
      " |  >>> imp_mean.transform(X)\n",
      " |  array([[ 6.9584...,  2.       ,  3.        ],\n",
      " |         [ 4.       ,  2.6000...,  6.        ],\n",
      " |         [10.       ,  4.9999...,  9.        ]])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  To support imputation in inductive mode we store each feature's estimator\n",
      " |  during the ``fit`` phase, and predict without refitting (in order) during\n",
      " |  the ``transform`` phase.\n",
      " |  \n",
      " |  Features which contain all missing values at ``fit`` are discarded upon\n",
      " |  ``transform``.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `Stef van Buuren, Karin Groothuis-Oudshoorn (2011). \"mice:\n",
      " |      Multivariate Imputation by Chained Equations in R\". Journal of\n",
      " |      Statistical Software 45: 1-67.\n",
      " |      <https://www.jstatsoft.org/article/view/v045i03>`_\n",
      " |  \n",
      " |  .. [2] `S. F. Buck, (1960). \"A Method of Estimation of Missing Values in\n",
      " |      Multivariate Data Suitable for use with an Electronic Computer\".\n",
      " |      Journal of the Royal Statistical Society 22(2): 302-306.\n",
      " |      <https://www.jstor.org/stable/2984099>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      IterativeImputer\n",
      " |      sklearn.impute._base._BaseImputer\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator=None, *, missing_values=nan, sample_posterior=False, max_iter=10, tol=0.001, n_nearest_features=None, initial_strategy='mean', imputation_order='ascending', skip_complete=False, min_value=-inf, max_value=inf, verbose=0, random_state=None, add_indicator=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fits the imputer on X and return self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Input data, where \"n_samples\" is the number of samples and\n",
      " |          \"n_features\" is the number of features.\n",
      " |      \n",
      " |      y : ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Fits the imputer on X and return the transformed X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Input data, where \"n_samples\" is the number of samples and\n",
      " |          \"n_features\" is the number of features.\n",
      " |      \n",
      " |      y : ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : array-like, shape (n_samples, n_features)\n",
      " |          The imputed input data.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Imputes all missing values in X.\n",
      " |      \n",
      " |      Note that this is stochastic, and that if random_state is not fixed,\n",
      " |      repeated calls, or permuted input, will yield different results.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input data to complete.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : array-like, shape (n_samples, n_features)\n",
      " |           The imputed input data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "help(IterativeImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotFrontage  MasVnrArea  GarageYrBlt\n",
      "0    -0.372911   -0.606613    -2.126354\n",
      "1    -0.678966   -0.606613    -1.927257\n",
      "2          NaN    0.706580     0.063711\n",
      "3     0.200943   -0.606613     0.422085\n",
      "4    -0.066855   -0.606613     1.138834\n",
      "   LotFrontage  MasVnrArea  GarageYrBlt\n",
      "0    -0.372911   -0.606613    -2.126354\n",
      "1    -0.678966   -0.606613    -1.927257\n",
      "2     0.522302    0.706580     0.063711\n",
      "3     0.200943   -0.606613     0.422085\n",
      "4    -0.066855   -0.606613     1.138834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.9/site-packages/sklearn/impute/_iterative.py:685: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(df_train[['LotFrontage','MasVnrArea','GarageYrBlt']].head())\n",
    "\n",
    "imputer = IterativeImputer(estimator = RandomForestRegressor(n_estimators=10, random_state=1000))\n",
    "X_impute = imputer.fit_transform(df_train)\n",
    "df_train_imp = pd.DataFrame(data=X_impute, columns = df_train.columns)\n",
    "\n",
    "print(df_train_imp[['LotFrontage','MasVnrArea','GarageYrBlt']].head())\n",
    "\n",
    "# save training data into a csv, we will use this csv in the next notebook\n",
    "df_train_imp.assign(SalePrice=y_train.values).to_csv('data/house_price_prep_imputed.csv',index=False)\n",
    "\n",
    "df_CV_imp = pd.DataFrame(data=imputer.transform(df_CV), columns = df_train.columns)\n",
    "df_test_imp = pd.DataFrame(data=imputer.transform(df_test), columns = df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multivariate imputation: uncertainty estimate\n",
    "\n",
    "- create multiple imputed datasets with different random states (at least 3 but 5 or more is recommended)\n",
    "- run each imputed dataset through your ML pipeline\n",
    "- measure the uncertainty of the predicted target variable (mean and stdev of each points' predicted labels)\n",
    "- this procedure will let you estimate the uncertainty due to the randomness in imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another lecture on missing data later!\n",
    "- there are advanced methods to deal with missing values in contunous features (without imputation)\n",
    "- but we need to cover a couple of other things first before we can discuss those techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 7, Quiz 4 on Canvas\n",
    "Consider how multivariate imputation works. Please explain in a couple of sentences why it fails for MNAR! Feel free to check out the paper of the method (pdf in the repository) or check out the sklearn pages below for more info!\n",
    "\n",
    "https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
