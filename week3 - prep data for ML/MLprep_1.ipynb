{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudcard\n",
    "- **Could you provide more tools to test the correlation between two input? For example, I am interested in the correlation between age and gross-income. Should I do a simple Pearson correlation?**\n",
    "    - Yes, we will cover quantitative ways to asses correlation between features during week4\n",
    "- **I am still unsure about how to assess the number of bins for some of the different visualizations.**\n",
    "    - It's by trial and error.\n",
    "    - there is no approach that will always give you the correct number of bins under all circumstances\n",
    "    - try a couple of values and be critical about your figure\n",
    "- **Are 3 dimensional/video visualization tools easily available?**\n",
    "- **What do you think of 3D visualizations? They can be effective (and abused) depending on the circumstances.**\n",
    "- **Are there any 3D visualization ways we can use? And when should we use them?**\n",
    "    - this is just my subjective opinion but I don't like 3D figures\n",
    "    - it's too distractive in my opinion\n",
    "- **what are other scales beyond logarithmic that are useful for axes?**\n",
    "    - if you use log instead of linear axis when appropriate, you are way ahead of the curve :)\n",
    "- **How to know what transform method should we choose when plotting a histogram, like 'log'?**\n",
    "    - trial and error\n",
    "    - experient until you are happy with the figure\n",
    "- **What is the difference between bar plot and histogram?**\n",
    "- **What is the difference between a histogram and a bar plot? Because from the plot, both of them are made up with bars.**\n",
    "    - the bars can be shuffled in a bar plot, it doesn't matter how you order the counts of the categories\n",
    "    - the bars in the histogram correspond to bins defined over the range of a continuous feature\n",
    "        - the height of the bars tells you how many points fall into each bin\n",
    "    - the bars of a histogram cannot be shuffled around\n",
    "- **Is there 'a best choice' of plot types for visualization? If not, do I need to include all the appropriate plots for a set of data when writing reports?**\n",
    "    - no, definitely not all plots\n",
    "    - a report or a presentation is a distilled version of your work\n",
    "    - you will work on a project for months if not years and the report is a couple of pages, the presentation is maybe 5 to 30 minutes\n",
    "    - you will do a lot more work than what goes into the report and presentation\n",
    "- **We spent a lot of time talking about visualization for EDA, which is just for our own understanding, but at what point do we stop the EDA and just get to the analysis. In other words, when do we know what we've done is good enough?**\n",
    "    - when will you be 100% sure that you absolutely and perfectly understand all aspects of your data?\n",
    "    - never\n",
    "    - but you have deadlines so at some point you need to move on and hope you have a sufficiently good understanding of your data\n",
    "- **I was unsure about what exactly the log=True argument did**\n",
    "    - run the code with and without it to figure this out\n",
    "- **How much of an emphasis will there be on data visualization in the course and will we be touching libraries outside of the python programming language like D3?**\n",
    "    - unfortunately we only have time for one lecture\n",
    "    - we won't work with anything outside of python\n",
    "    - and we won't even have time to learn all the visualization packages within python\n",
    "    - as I said, data visualization could be a separate course\n",
    "- **What if we have ordinary data in our dataset? Should we treat them as categorical or continuous variables when visualizing figures?**\n",
    "    - that's exactly the point of Georgie charts I showed during the last lecture\n",
    "    - it's categorical but you need to make sure that the categories are displayed in the correct order in your figure (like the months or dates, etc.).\n",
    "- **When we get NA or \"?\" as a part of our data and its fraction is significant in the data set, what is the standard practice in addressing how it affects our data set?**\n",
    "    - week 4 and week 9 :)\n",
    "    - we will cover several techniques\n",
    "    - there is no standard\n",
    "    - you need to decide which approach is best given your problem, computational resources, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split iid and non-iid data\n",
    "By the end of this lecture, you will be able to\n",
    "- apply a basic split and a k-fold split to iid datasets\n",
    "- apply stratified splits to imbalanced data\n",
    "- split non-iid data based on group ID or time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The supervised ML pipeline\n",
    "The goal: Use the training data (X and y) to develop a <font color='red'>model</font> which can <font color='red'>accurately</font> predict the target variable (y_new') for previously unseen data (X_new).\n",
    "\n",
    "**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)</span>\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "**4. Choose an evaluation metric**: depends on the priorities of the stakeholders\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we split the data?\n",
    "- we want to find the best hyper-parameters of our ML algorithms\n",
    "   - fit models to training data\n",
    "   - evaluate each model on validation set\n",
    "   - we find hyper-parameter values that optimize the validation score\n",
    "- we want to know how the model will perform on previously unseen data\n",
    "   - apply our final model on the test set\n",
    "   \n",
    "### We need to split the data into three parts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How should we split the data into train/validation/test?\n",
    "\n",
    "- data is **Independent and Identically Distributed** (iid)\n",
    "   - all samples stem from the same generative process and the generative process is assumed to have no memory of past generated samples\n",
    "   - identify cats and dogs on images\n",
    "   - predict the house price\n",
    "   - predict if someone's salary is above or below 50k\n",
    "- examples of not iid data:\n",
    "   - data generated by time-dependent processes\n",
    "   - data has group structure (samples collected from e.g., different subjects, experiments, measurement devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='lightgray'>Split iid and non-iid data</font>\n",
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- **apply a basic split and a k-fold split to iid datasets**\n",
    "- <font color='lightgray'>apply stratified splits to imbalanced data</font>\n",
    "- <font color='lightgray'>split non-iid data based on group ID or time</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Splitting strategies for iid data: basic approach\n",
    "- 60% train, 20% validation, 20% test for small datasets\n",
    "- 98% train, 1% validation, 1% test for large datasets\n",
    "    - if you have 1 million points, you still have 10000 points in validation and test which is plenty to assess model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's work with the adult data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         <=50K.\n",
      "1         <=50K.\n",
      "2          >50K.\n",
      "3          >50K.\n",
      "4         <=50K.\n",
      "          ...   \n",
      "16276     <=50K.\n",
      "16277     <=50K.\n",
      "16278     <=50K.\n",
      "16279     <=50K.\n",
      "16280      >50K.\n",
      "Name: gross-income, Length: 16281, dtype: object\n",
      "   age   workclass  fnlwgt      education  education-num       marital-status  \\\n",
      "0   25     Private  226802           11th              7        Never-married   \n",
      "1   38     Private   89814        HS-grad              9   Married-civ-spouse   \n",
      "2   28   Local-gov  336951     Assoc-acdm             12   Married-civ-spouse   \n",
      "3   44     Private  160323   Some-college             10   Married-civ-spouse   \n",
      "4   18           ?  103497   Some-college             10        Never-married   \n",
      "\n",
      "           occupation relationship    race      sex  capital-gain  \\\n",
      "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
      "1     Farming-fishing      Husband   White     Male             0   \n",
      "2     Protective-serv      Husband   White     Male             0   \n",
      "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
      "4                   ?    Own-child   White   Female             0   \n",
      "\n",
      "   capital-loss  hours-per-week  native-country  \n",
      "0             0              40   United-States  \n",
      "1             0              50   United-States  \n",
      "2             0              40   United-States  \n",
      "3             0              40   United-States  \n",
      "4             0              30   United-States  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('data/adult_test.csv')\n",
    "\n",
    "# let's separate the feature matrix X, and target variable y\n",
    "y = df['gross-income'] # remember, we want to predict who earns more than 50k or less than 50k\n",
    "X = df.loc[:, df.columns != 'gross-income'] # all other columns are features\n",
    "print(y)\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: (9768, 14) (9768,)\n",
      "(6513, 14) (6513,)\n",
      "validation set: (3256, 14) (3256,)\n",
      "test set: (3257, 14) (3257,)\n",
      "       age          workclass  fnlwgt      education  education-num  \\\n",
      "4050    22            Private  335950        HS-grad              9   \n",
      "11446   29            Private   78261        HS-grad              9   \n",
      "12427   74   Self-emp-not-inc  160009     Assoc-acdm             12   \n",
      "5702    39       Self-emp-inc   31709   Some-college             10   \n",
      "13058   50            Private  144084        HS-grad              9   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "4050         Never-married     Other-service   Not-in-family   Black     Male   \n",
      "11446            Separated   Protective-serv   Not-in-family   White     Male   \n",
      "12427   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "5702    Married-civ-spouse      Adm-clerical            Wife   White   Female   \n",
      "13058            Separated             Sales       Unmarried   White   Female   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country  \n",
      "4050              0             0              70   United-States  \n",
      "11446             0             0              55   United-States  \n",
      "12427             0             0              30   United-States  \n",
      "5702              0             0              20   United-States  \n",
      "13058             0             0              55   United-States  \n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=random_state)\n",
    "print('training set:',X_train.shape, y_train.shape) # 60% of points are in train\n",
    "print(X_other.shape, y_other.shape) # 40% of points are in other\n",
    "\n",
    "# second split to separate out the validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=random_state)\n",
    "print('validation set:',X_val.shape, y_val.shape) # 20% of points are in validation\n",
    "print('test set:',X_test.shape, y_test.shape) # 20% of points are in test\n",
    "\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomness due to splitting\n",
    "- the model performance, validation and test scores will change depending on which points are in train, val, test\n",
    "    - inherent randomness or uncertainty of the ML pipeline\n",
    "- change the random state a couple of times and repeat the whole ML pipeline to assess how much the random splitting affects your test score\n",
    "    - you would expect a similar uncertainty when the model is deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting strategies for iid data: k-fold splitting\n",
    "\n",
    "<center><img src=\"figures/grid_search_cross_validation.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KFold in module sklearn.model_selection._split:\n",
      "\n",
      "class KFold(_BaseKFold)\n",
      " |  KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      " |  \n",
      " |  K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets. Split\n",
      " |  dataset into k consecutive folds (without shuffling by default).\n",
      " |  \n",
      " |  Each fold is then used once as a validation while the k - 1 remaining\n",
      " |  folds form the training set.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <k_fold>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |  \n",
      " |  shuffle : bool, default=False\n",
      " |      Whether to shuffle the data before splitting into batches.\n",
      " |      Note that the samples within each split will not be shuffled.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      " |      indices, which controls the randomness of each fold. Otherwise, this\n",
      " |      parameter has no effect.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import KFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([1, 2, 3, 4])\n",
      " |  >>> kf = KFold(n_splits=2)\n",
      " |  >>> kf.get_n_splits(X)\n",
      " |  2\n",
      " |  >>> print(kf)\n",
      " |  KFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in kf.split(X):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [2 3] TEST: [0 1]\n",
      " |  TRAIN: [0 1] TEST: [2 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The first ``n_samples % n_splits`` folds have size\n",
      " |  ``n_samples // n_splits + 1``, other folds have size\n",
      " |  ``n_samples // n_splits``, where ``n_samples`` is the number of samples.\n",
      " |  \n",
      " |  Randomized CV splitters may return different results for each call of\n",
      " |  split. You can make the results identical by setting `random_state`\n",
      " |  to an integer.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  StratifiedKFold : Takes group information into account to avoid building\n",
      " |      folds with imbalanced class distributions (for binary or multiclass\n",
      " |      classification tasks).\n",
      " |  \n",
      " |  GroupKFold : K-fold iterator variant with non-overlapping groups.\n",
      " |  \n",
      " |  RepeatedKFold : Repeats K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,), default=None\n",
      " |          The target variable for supervised learning problems.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "help(KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13024, 14) (13024,)\n",
      "test set: (3257, 14) (3257,)\n",
      "   training set: (10419, 14) (10419,)\n",
      "   validation set: (2605, 14) (2605,)\n",
      "       age          workclass      education\n",
      "9850    59            Private   Some-college\n",
      "103     58   Self-emp-not-inc            9th\n",
      "1383    45            Private        HS-grad\n",
      "11034   49   Self-emp-not-inc      Bachelors\n",
      "14876   59   Self-emp-not-inc      Bachelors\n",
      "   training set: (10419, 14) (10419,)\n",
      "   validation set: (2605, 14) (2605,)\n",
      "       age     workclass      education\n",
      "13384   60   Federal-gov      Bachelors\n",
      "8471    20       Private        HS-grad\n",
      "13406   21             ?   Some-college\n",
      "13394   35       Private        HS-grad\n",
      "15123   38       Private   Some-college\n",
      "   training set: (10419, 14) (10419,)\n",
      "   validation set: (2605, 14) (2605,)\n",
      "       age     workclass      education\n",
      "647     60             ?      Bachelors\n",
      "9314    26       Private   Some-college\n",
      "14499   52       Private        HS-grad\n",
      "7332    53   Federal-gov     Assoc-acdm\n",
      "12523   21       Private           10th\n",
      "   training set: (10419, 14) (10419,)\n",
      "   validation set: (2605, 14) (2605,)\n",
      "       age workclass      education\n",
      "5294    53   Private        HS-grad\n",
      "3481    41   Private        HS-grad\n",
      "7671    49   Private   Some-college\n",
      "11055   39   Private      Bachelors\n",
      "12751   18         ?           12th\n",
      "   training set: (10420, 14) (10420,)\n",
      "   validation set: (2604, 14) (2604,)\n",
      "       age      workclass     education\n",
      "4265    23              ?          10th\n",
      "5290    23        Private       HS-grad\n",
      "1157    56   Self-emp-inc   Prof-school\n",
      "12344   18        Private          11th\n",
      "13683   55        Private       HS-grad\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "# first split to separate out the test set\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "print(X_other.shape,y_other.shape)\n",
    "print('test set:',X_test.shape,y_test.shape)\n",
    "\n",
    "# do KFold split on other\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print('   training set:',X_train.shape, y_train.shape) \n",
    "    print('   validation set:',X_val.shape, y_val.shape) \n",
    "    # the validation set contains different points in each iteration\n",
    "    print(X_val[['age','workclass','education']].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How many splits should I create?\n",
    "- tough question, 3-5 is most common\n",
    "- if you do n splits, n models will be trained, so the larger the n, the most computationally intensive it will be to train the models\n",
    "- KFold is usually better suited to small datasets\n",
    "- KFold is good to estimate uncertainty due to random splitting of train and val, but it is not perfect\n",
    "    - the test set remains the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why shuffling iid data is important?\n",
    "- by default, data is not shuffled by Kfold which can introduce errors!\n",
    "<center><img src=\"figures/kfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1\n",
    "\n",
    "Split the adult dataset into 70% train, 20% validation, and 10% test! How many points do we have in train, validation, test? Give your answer in the following format:\n",
    "\n",
    "i, j, k\n",
    "\n",
    "where i is the number of points in train, j is the number of points in validation, and k is the number of points in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16281, 14)\n",
      "other set: (14652, 14) (14652,)\n",
      "test set (1629, 14) (1629,)\n",
      "validation set: (3256, 14) (3256,)\n",
      "train set: (11396, 14) (11396,)\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.1,random_state=random_state)\n",
    "print('other set:',X_other.shape, y_other.shape) # 60% of points are in train\n",
    "print('test set',X_test.shape, y_test.shape) # 40% of points are in other\n",
    "\n",
    "# second split to separate out the validation and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_other,y_other,train_size = 7/9,random_state=random_state)\n",
    "print('validation set:',X_val.shape, y_val.shape) # 20% of points are in validation\n",
    "print('train set:',X_train.shape, y_train.shape) # 20% of points are in test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='lightgray'>Split iid and non-iid data</font>\n",
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='lightgray'>apply a basic split and a k-fold split to iid datasets</font>\n",
    "- **apply stratified splits to imbalanced data**\n",
    "- <font color='lightgray'>split non-iid data based on group ID or time</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced data\n",
    "- imbalanced data: only a small fraction of the points are in one of the classes, usually ~5% or less but there is no hard limit here\n",
    "- examples:\n",
    "    - people visit a bank's website. do they sign up for a new credit card?\n",
    "        - most customers just browse and leave the page\n",
    "        - usually 1% or less of the customers get a credit card (class 1), the rest leaves the page without signing up (class 0).\n",
    "    - fraud detection\n",
    "        - only a tiny fraction of credit card payments are fraudulent\n",
    "    - rare disease diagnosis\n",
    "- the issue with imbalanced data:\n",
    "    - if you apply train_test_split or KFold, you might not have class 1 points in one of your sets by chance\n",
    "    - this is what we need to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: stratified splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**balance without stratification:**\n",
      " <=50K.    0.76423\n",
      " >50K.     0.23577\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K.    0.770885\n",
      " >50K.     0.229115\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K.    0.755296\n",
      " >50K.     0.244704\n",
      "Name: gross-income, dtype: float64\n",
      "\n",
      "**balance with stratification:**\n",
      " <=50K.    0.763821\n",
      " >50K.     0.236179\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K.    0.763821\n",
      " >50K.     0.236179\n",
      "Name: gross-income, dtype: float64\n",
      " <=50K.    0.763586\n",
      " >50K.     0.236414\n",
      "Name: gross-income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "random_state = 137\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,random_state=random_state)\n",
    "\n",
    "print('**balance without stratification:**')\n",
    "# a variation on the order of 1% which would be too much for imbalanced data!\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "print()\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=y,random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=y_other,random_state=random_state)\n",
    "print('**balance with stratification:**')\n",
    "# very little variation (in the 4th decimal point only) which is important if the problem is imbalanced\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stratified folds\n",
    "<center><img src=\"figures/stratified_kfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StratifiedKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class StratifiedKFold(_BaseKFold)\n",
      " |  StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      " |  \n",
      " |  Stratified K-Folds cross-validator.\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets.\n",
      " |  \n",
      " |  This cross-validation object is a variation of KFold that returns\n",
      " |  stratified folds. The folds are made by preserving the percentage of\n",
      " |  samples for each class.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <stratified_k_fold>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |  \n",
      " |  shuffle : bool, default=False\n",
      " |      Whether to shuffle each class's samples before splitting into batches.\n",
      " |      Note that the samples within each split will not be shuffled.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      " |      indices, which controls the randomness of each fold for each class.\n",
      " |      Otherwise, leave `random_state` as `None`.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import StratifiedKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([0, 0, 1, 1])\n",
      " |  >>> skf = StratifiedKFold(n_splits=2)\n",
      " |  >>> skf.get_n_splits(X, y)\n",
      " |  2\n",
      " |  >>> print(skf)\n",
      " |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in skf.split(X, y):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [1 3] TEST: [0 2]\n",
      " |  TRAIN: [0 2] TEST: [1 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The implementation is designed to:\n",
      " |  \n",
      " |  * Generate test sets such that all contain the same distribution of\n",
      " |    classes, or as close as possible.\n",
      " |  * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
      " |    ``y = [1, 0]`` should not change the indices generated.\n",
      " |  * Preserve order dependencies in the dataset ordering, when\n",
      " |    ``shuffle=False``: all samples from class k in some test set were\n",
      " |    contiguous in y, or separated in y by samples from classes other than k.\n",
      " |  * Generate test sets where the smallest and largest differ by at most one\n",
      " |    sample.\n",
      " |  \n",
      " |  .. versionchanged:: 0.22\n",
      " |      The previous implementation did not follow the last constraint.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StratifiedKFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  split(self, X, y, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |          Note that providing ``y`` is sufficient to generate the splits and\n",
      " |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      " |          ``X`` instead of actual training data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |          Stratification is done based on the y labels.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting `random_state`\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "help(StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test balance:  <=50K.    0.770648\n",
      " >50K.     0.229352\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.760726\n",
      " >50K.     0.239274\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.76737\n",
      " >50K.     0.23263\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.761781\n",
      " >50K.     0.238219\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763148\n",
      " >50K.     0.236852\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.761685\n",
      " >50K.     0.238315\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763532\n",
      " >50K.     0.236468\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.761014\n",
      " >50K.     0.238986\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.766219\n",
      " >50K.     0.233781\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.765067\n",
      " >50K.     0.234933\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.75\n",
      " >50K.     0.25\n",
      "Name: gross-income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# what we did before: variance in balance on the order of 1%\n",
    "random_state = 42\n",
    "\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=random_state)\n",
    "print('test balance:',y_test.value_counts(normalize=True))\n",
    "\n",
    "# do KFold split on other\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print('train balance:')\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print('val balance:')\n",
    "    print(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test balance:  <=50K.    0.763893\n",
      " >50K.     0.236107\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.763701\n",
      " >50K.     0.236299\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763916\n",
      " >50K.     0.236084\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.763701\n",
      " >50K.     0.236299\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763916\n",
      " >50K.     0.236084\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.763797\n",
      " >50K.     0.236203\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763532\n",
      " >50K.     0.236468\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.763797\n",
      " >50K.     0.236203\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763532\n",
      " >50K.     0.236468\n",
      "Name: gross-income, dtype: float64\n",
      "train balance:\n",
      " <=50K.    0.763724\n",
      " >50K.     0.236276\n",
      "Name: gross-income, dtype: float64\n",
      "val balance:\n",
      " <=50K.    0.763825\n",
      " >50K.     0.236175\n",
      "Name: gross-income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# stratified K Fold: variation in balance is very small (4th decimal point)\n",
    "random_state = 42\n",
    "\n",
    "# stratified train-test split\n",
    "X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,stratify=y,random_state=random_state)\n",
    "print('test balance:',y_test.value_counts(normalize=True))\n",
    "\n",
    "# do StratifiedKFold split on other\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "for train_index, val_index in kf.split(X_other,y_other):\n",
    "    X_train = X_other.iloc[train_index]\n",
    "    y_train = y_other.iloc[train_index]\n",
    "    X_val = X_other.iloc[val_index]\n",
    "    y_val = y_other.iloc[val_index]\n",
    "    print('train balance:')\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print('val balance:')\n",
    "    print(y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz 2\n",
    "Given the labels below, what are the balances of each class?\n",
    "\n",
    "y = [0,0,0,2,2,0,1,2,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='lightgray'>Split iid and non-iid data</font>\n",
    "<font color='lightgray'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='lightgray'>apply a basic split and a k-fold split to iid datasets</font>\n",
    "- <font color='lightgray'>apply stratified splits to imbalanced data</font>\n",
    "- **split non-iid data based on group ID or time**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of non-iid data\n",
    "- if there is any sort of time or group structure in your data, it is likely non-iid\n",
    "    - group structure:\n",
    "        - each point is someone's visit to the ER and some people visited the ER multiple times\n",
    "        - each point is stats of a youtube video and the stats are collected weekly, one of the stats is whether it is featured\n",
    "        - each point is a customer's visit to CVS and customers tend to return regularly\n",
    "    - time structure\n",
    "        - each point is the stocks price at a given time\n",
    "        - eahc point is a person's health or activity status\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask yourself these questions!\n",
    "- What is the intended use of the model? What is it supposed to do/predict?\n",
    "- What data do you have available at the time of prediction?\n",
    "- Your split must mimic the intended use of the model only then will you accurately estimate how well the model will perform on previously unseen points (generalization error).\n",
    "- two examples:\n",
    "    - if you want to predict the outcome of a new patient's visit to the ER:\n",
    "        - your test score must be based on patients not included in training and validation\n",
    "        - your validation score must be based on patients not included in training\n",
    "        - points of one patient should not be distributed over multiple sets because your generalization error will be off\n",
    "    - a youtube video was released 4 weeks ago and you want to predict if it will be featured a week from now, your training data should only contain info that will available upon predictions (stuff you know 4 weeks after release)\n",
    "        - split data based on youtube vid ID\n",
    "        - use info that's available 4 weeks after release\n",
    "        - your classification label will be whether it was featured or not 5 weeks after release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-based split: GroupShuffleSplit\n",
    "<center><img src=\"figures/groupshufflesplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "X = np.ones(shape=(8, 2))\n",
    "y = np.ones(shape=(8, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=10, train_size=.8, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-based split: GroupKFold\n",
    "<center><img src=\"figures/groupkfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [5 6 7]\n",
      "TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GroupKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class GroupKFold(_BaseKFold)\n",
      " |  GroupKFold(n_splits=5)\n",
      " |  \n",
      " |  K-fold iterator variant with non-overlapping groups.\n",
      " |  \n",
      " |  The same group will not appear in two different folds (the number of\n",
      " |  distinct groups has to be at least equal to the number of folds).\n",
      " |  \n",
      " |  The folds are approximately balanced in the sense that the number of\n",
      " |  distinct groups is approximately the same in each fold.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <group_k_fold>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=5\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``n_splits`` default value changed from 3 to 5.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import GroupKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      " |  >>> y = np.array([1, 2, 3, 4])\n",
      " |  >>> groups = np.array([0, 0, 2, 2])\n",
      " |  >>> group_kfold = GroupKFold(n_splits=2)\n",
      " |  >>> group_kfold.get_n_splits(X, y, groups)\n",
      " |  2\n",
      " |  >>> print(group_kfold)\n",
      " |  GroupKFold(n_splits=2)\n",
      " |  >>> for train_index, test_index in group_kfold.split(X, y, groups):\n",
      " |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      " |  ...     print(X_train, X_test, y_train, y_test)\n",
      " |  ...\n",
      " |  TRAIN: [0 1] TEST: [2 3]\n",
      " |  [[1 2]\n",
      " |   [3 4]] [[5 6]\n",
      " |   [7 8]] [1 2] [3 4]\n",
      " |  TRAIN: [2 3] TEST: [0 1]\n",
      " |  [[5 6]\n",
      " |   [7 8]] [[1 2]\n",
      " |   [3 4]] [3 4] [1 2]\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  LeaveOneGroupOut : For splitting the data according to explicit\n",
      " |      domain-specific stratification of the dataset.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GroupKFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits=5)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,), default=None\n",
      " |          The target variable for supervised learning problems.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,)\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GroupKFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data leakage in time series data is similar!\n",
    "- do NOT use information in validation or test which will not be available once your model is deployed\n",
    "   - don't use future information!\n",
    "   \n",
    "<center><img src=\"figures/timeseriessplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n",
      "TRAIN: [0 1 2 3] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit()\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 3\n",
    "Go back to the GroupKFold example above. What happens when you change n_splits to 4? Why?\n",
    "\n",
    "Why could we set the n_splits argument to 5 in GroupShuffleSplit? \n",
    "\n",
    "Explain your answer in a couple of sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
